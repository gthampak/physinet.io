{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Dataset\n",
    "\n",
    "Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random; random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "#import tensorflow as tf # tensorflow-gpu==2.0.0\n",
    "#from tensorflow.python.client import device_lib \n",
    "#print(device_lib.list_local_devices())\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/train'\n",
    "train_dir_video = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_h264/train'\n",
    "\n",
    "# test data\n",
    "test_inputs_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/test_inputs/'\n",
    "test_targets_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/test_targets/'\n",
    "test_targets_video = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_h264/test_targets/'\n",
    "\n",
    "# validation data\n",
    "validation_inputs_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/validation_inputs/'\n",
    "validation_targets_dir = 'tData/rain_and_test_split/dpc_dataset_traintest_4_200_csv/validation_targets/'\n",
    "validation_targets_video = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_h264/validation_targets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate based predictions:\n",
    "### Data Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants\n",
    "DEFAULT_X_RED, DEFAULT_Y_RED = (240, 240)\n",
    "\n",
    "PIXEL_DISTANCE_GREEN_TO_RED = 118 # approx. value | calculated with the Pythagorean theorem and averaged: np.sqrt((y_green-y_red)**2 + (x_green-x_red)**2)\n",
    "PIXEL_DISTANCE_BLUE_TO_GREEN = 90 # approx. value | calculated with the Pythagorean theorem and averaged: np.sqrt((y_blue-y_green)**2 + (x_blue-x_green)**2)\n",
    "\n",
    "def raw_to_pixel(l):\n",
    "    '''Convert the raw coordinates to pixel coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    return [x/5 for x in l]\n",
    "\n",
    "\n",
    "def pixel_to_raw(l):\n",
    "    '''Convert the pixel coordinates to raw coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    return [x*5 for x in l]\n",
    "\n",
    "\n",
    "def raw_cartesian_to_polar_angles(l):\n",
    "    '''Convert the cartesian coordinates to polar coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    x_red, y_red, x_green, y_green, x_blue, y_blue = raw_to_pixel(l)\n",
    "\n",
    "    angle_green_red = np.arctan((y_green-y_red)/(x_green-x_red+0.001))\n",
    "    angle_blue_green = np.arctan((y_blue-y_green)/(x_blue-x_green+0.001))\n",
    "    \n",
    "    return [np.sin(angle_green_red), np.cos(angle_green_red), np.sin(angle_blue_green), np.cos(angle_blue_green)]\n",
    "\n",
    "def polar_angles_to_raw_cartesian(l):\n",
    "    '''Convert the polar coordinates back to cartesian coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    sin_angle_green_red, cos_angle_green_red, sin_angle_blue_green, cos_angle_blue_green = l\n",
    "    \n",
    "    y_green = PIXEL_DISTANCE_GREEN_TO_RED * sin_angle_green_red + DEFAULT_Y_RED\n",
    "    x_green = PIXEL_DISTANCE_GREEN_TO_RED * cos_angle_green_red + DEFAULT_X_RED\n",
    "\n",
    "    y_blue = PIXEL_DISTANCE_BLUE_TO_GREEN * sin_angle_blue_green + y_green\n",
    "    x_blue = PIXEL_DISTANCE_BLUE_TO_GREEN * cos_angle_blue_green + x_green\n",
    "    \n",
    "    return pixel_to_raw([DEFAULT_X_RED, DEFAULT_Y_RED, x_green, y_green, x_blue, y_blue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the raw -> pixel conversion and pixel -> raw works as intended, and that the cartesian -> polar conversion and polar -> cartesian conversion works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_coordinates = list(np.array([240, 240, 357.4438349670886, 228.55685234634907, 444.41827493559794, 205.41712909467287])*5)\n",
    "pixel_coordinates = raw_to_pixel(raw_coordinates)\n",
    "new_raw_coordinates = pixel_to_raw(pixel_coordinates)\n",
    "assert raw_coordinates == new_raw_coordinates, '`Raw -> Pixel` and `Pixel -> Raw` coordinate conversion methods are malfunctioning.'\n",
    "\n",
    "raw_cartesian = list(np.array([240, 240, 357.4438349670886, 228.55685234634907, 444.41827493559794, 205.41712909467287])*5)\n",
    "polar = raw_cartesian_to_polar_angles(raw_cartesian)\n",
    "new_raw_cartesian = polar_angles_to_raw_cartesian(polar)\n",
    "assert [round(x) for x in raw_cartesian] == [round(x) for x in new_raw_cartesian], 'Cartesian to Polar and Polar to Cartesian methods are malfunctioning.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data reading functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing training data:\n",
    "training data x-y matching is like this:\n",
    "x: a list of 4 frames\n",
    "y: the frame that follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_training_annotations(csv_file):\n",
    "    '''Parse the training annotations from a CSV file.'''\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    f = pd.read_csv(csv_file, header=None, delim_whitespace=True, engine='python')\n",
    "    temp = []\n",
    "    for i, row in f.iterrows():\n",
    "        if len(temp) < 4:\n",
    "            # convert the cartesian pixel coordinates to polar coordinates\n",
    "            temp.append(raw_cartesian_to_polar_angles(row.to_list()))\n",
    "        else:\n",
    "            # the output frame\n",
    "            # convert the cartesian pixel coordinates to polar coordinates\n",
    "            next_frame = raw_cartesian_to_polar_angles(row.to_list())\n",
    "\n",
    "            # save\n",
    "            X_data.append(temp)\n",
    "            y_data.append(next_frame.copy())\n",
    "\n",
    "            # add output frame to the inputs and remove the first\n",
    "            temp.pop(0)\n",
    "            temp.append(next_frame)\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:57<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4000\n",
    "\n",
    "# load in all separate files\n",
    "X = []\n",
    "y = []\n",
    "for filename in tqdm([x for x in os.listdir(train_dir) if not x.startswith('.')]):\n",
    "    # load in a file\n",
    "    X_data, y_data = parse_training_annotations(os.path.join(train_dir, filename))\n",
    "\n",
    "    X = X + X_data\n",
    "    y = y + y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublePendulumDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X_list,y_list):\n",
    "        self.sample_list = list(zip(X_list, y_list))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        X_sample,y_sample = self.sample_list[index]\n",
    "        return torch.from_numpy(np.array(X_sample)).float(),torch.from_numpy(np.array(y_sample)).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataSet = DoublePendulumDataset(X,y)\n",
    "myDataLoader = torch.utils.data.DataLoader(myDataSet,batch_size=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # We want a model of 4 layer LSTM with 32 features output, and a dense layer to form the 4 feature output.\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_size = 32\n",
    "        self.n_layers = 4\n",
    "\n",
    "        #Defining the layers\n",
    "        # LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size = 4, hidden_size = 32, num_layers = 1, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(input_size = 32, hidden_size = 32, num_layers = 1, batch_first = True)\n",
    "        self.lstm3 = nn.LSTM(input_size = 32, hidden_size = 32, num_layers = 1, batch_first = True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1, _= self.lstm1(x) # (h0.detach(), c0.detach())\n",
    "        out2, _= self.lstm2(out1)\n",
    "        out3, _= self.lstm3(out2)\n",
    "        out3 = out3[:, -1, :]\n",
    "        out = self.fc(out3)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model()\n",
    "model.train()\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 10\n",
    "lr=0.001\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "[1,    20] loss: 0.005\n",
      "[1,    40] loss: 0.004\n",
      "[1,    60] loss: 0.003\n",
      "[1,    80] loss: 0.003\n",
      "[2,    20] loss: 0.003\n",
      "[2,    40] loss: 0.003\n",
      "[2,    60] loss: 0.003\n",
      "[2,    80] loss: 0.003\n",
      "[3,    20] loss: 0.003\n",
      "[3,    40] loss: 0.003\n",
      "[3,    60] loss: 0.003\n",
      "[3,    80] loss: 0.003\n",
      "[4,    20] loss: 0.003\n",
      "[4,    40] loss: 0.003\n",
      "[4,    60] loss: 0.003\n",
      "[4,    80] loss: 0.003\n",
      "[5,    20] loss: 0.003\n",
      "[5,    40] loss: 0.003\n",
      "[5,    60] loss: 0.003\n",
      "[5,    80] loss: 0.003\n",
      "[6,    20] loss: 0.003\n",
      "[6,    40] loss: 0.003\n",
      "[6,    60] loss: 0.003\n",
      "[6,    80] loss: 0.003\n",
      "[7,    20] loss: 0.003\n",
      "[7,    40] loss: 0.003\n",
      "[7,    60] loss: 0.003\n",
      "[7,    80] loss: 0.003\n",
      "[8,    20] loss: 0.003\n",
      "[8,    40] loss: 0.003\n",
      "[8,    60] loss: 0.003\n",
      "[8,    80] loss: 0.003\n",
      "[9,    20] loss: 0.003\n",
      "[9,    40] loss: 0.003\n",
      "[9,    60] loss: 0.003\n",
      "[9,    80] loss: 0.003\n",
      "[10,    20] loss: 0.003\n",
      "[10,    40] loss: 0.003\n",
      "[10,    60] loss: 0.003\n",
      "[10,    80] loss: 0.003\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('Training Start')\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(myDataLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200, 1200, 1507.199764251709, 1198.0677634477615, 1790.7197713851929, 1188.3616235107183]\n"
     ]
    }
   ],
   "source": [
    "testing_raw_list = [[1199,1160,1414,1711,1818,1509],[1199,1160,1412,1712,1814,1505],[1200,1160,1411,1712,1811,1501],[1200,1160,1411,1712,1808,1497]]\n",
    "testing_X = []\n",
    "for entry in testing_raw_list:\n",
    "    testing_X.append(raw_cartesian_to_polar_angles(entry))\n",
    "test_out = model(torch.from_numpy(np.array(testing_X).reshape(1,4,4)).float())\n",
    "test_out_list = test_out.tolist()\n",
    "test_out_polar = polar_angles_to_raw_cartesian(test_out_list[0])\n",
    "print(test_out_polar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9950993fed0fd9aed4b27a856c953e397ab7787bcf7b4a95697366d9a811f382"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('cs152': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
