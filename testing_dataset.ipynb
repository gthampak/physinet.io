{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Dataset\n",
    "\n",
    "Dependencies:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import os\n",
    "import shutil\n",
    "import random; random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "#import tensorflow as tf # tensorflow-gpu==2.0.0\n",
    "#from tensorflow.python.client import device_lib \n",
    "#print(device_lib.list_local_devices())\n",
    "#import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Directories:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# training data\n",
    "train_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/train'\n",
    "train_dir_video = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_h264/train'\n",
    "\n",
    "# test data\n",
    "test_inputs_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/test_inputs/'\n",
    "test_targets_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/test_targets/'\n",
    "test_targets_video = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_h264/test_targets/'\n",
    "\n",
    "# validation data\n",
    "validation_inputs_dir = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_csv/validation_inputs/'\n",
    "validation_targets_dir = 'tData/rain_and_test_split/dpc_dataset_traintest_4_200_csv/validation_targets/'\n",
    "validation_targets_video = 'Data/train_and_test_split/dpc_dataset_traintest_4_200_h264/validation_targets/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Coordinate based predictions:\n",
    "### Data Transformation Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# some constants\n",
    "DEFAULT_X_RED, DEFAULT_Y_RED = (240, 240)\n",
    "\n",
    "PIXEL_DISTANCE_GREEN_TO_RED = 118 # approx. value | calculated with the Pythagorean theorem and averaged: np.sqrt((y_green-y_red)**2 + (x_green-x_red)**2)\n",
    "PIXEL_DISTANCE_BLUE_TO_GREEN = 90 # approx. value | calculated with the Pythagorean theorem and averaged: np.sqrt((y_blue-y_green)**2 + (x_blue-x_green)**2)\n",
    "\n",
    "def raw_to_pixel(l):\n",
    "    '''Convert the raw coordinates to pixel coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    return [x/5 for x in l]\n",
    "\n",
    "\n",
    "def pixel_to_raw(l):\n",
    "    '''Convert the pixel coordinates to raw coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    return [x*5 for x in l]\n",
    "\n",
    "\n",
    "def raw_cartesian_to_polar_angles(l):\n",
    "    '''Convert the cartesian coordinates to polar coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    x_red, y_red, x_green, y_green, x_blue, y_blue = raw_to_pixel(l)\n",
    "\n",
    "    angle_green_red = np.arctan((y_green-y_red)/(x_green-x_red+0.001))\n",
    "    angle_blue_green = np.arctan((y_blue-y_green)/(x_blue-x_green+0.001))\n",
    "    \n",
    "    return [np.sin(angle_green_red), np.cos(angle_green_red), np.sin(angle_blue_green), np.cos(angle_blue_green)]\n",
    "\n",
    "def polar_angles_to_raw_cartesian(l):\n",
    "    '''Convert the polar coordinates back to cartesian coordinates.'''\n",
    "    assert isinstance(l, list)\n",
    "    sin_angle_green_red, cos_angle_green_red, sin_angle_blue_green, cos_angle_blue_green = l\n",
    "    \n",
    "    y_green = PIXEL_DISTANCE_GREEN_TO_RED * sin_angle_green_red + DEFAULT_Y_RED\n",
    "    x_green = PIXEL_DISTANCE_GREEN_TO_RED * cos_angle_green_red + DEFAULT_X_RED\n",
    "\n",
    "    y_blue = PIXEL_DISTANCE_BLUE_TO_GREEN * sin_angle_blue_green + y_green\n",
    "    x_blue = PIXEL_DISTANCE_BLUE_TO_GREEN * cos_angle_blue_green + x_green\n",
    "    \n",
    "    return pixel_to_raw([DEFAULT_X_RED, DEFAULT_Y_RED, x_green, y_green, x_blue, y_blue])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify that the raw -> pixel conversion and pixel -> raw works as intended, and that the cartesian -> polar conversion and polar -> cartesian conversion works as intended."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "raw_coordinates = list(np.array([240, 240, 357.4438349670886, 228.55685234634907, 444.41827493559794, 205.41712909467287])*5)\n",
    "pixel_coordinates = raw_to_pixel(raw_coordinates)\n",
    "new_raw_coordinates = pixel_to_raw(pixel_coordinates)\n",
    "assert raw_coordinates == new_raw_coordinates, '`Raw -> Pixel` and `Pixel -> Raw` coordinate conversion methods are malfunctioning.'\n",
    "\n",
    "raw_cartesian = list(np.array([240, 240, 357.4438349670886, 228.55685234634907, 444.41827493559794, 205.41712909467287])*5)\n",
    "polar = raw_cartesian_to_polar_angles(raw_cartesian)\n",
    "new_raw_cartesian = polar_angles_to_raw_cartesian(polar)\n",
    "assert [round(x) for x in raw_cartesian] == [round(x) for x in new_raw_cartesian], 'Cartesian to Polar and Polar to Cartesian methods are malfunctioning.'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data reading functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def parse_training_annotations(csv_file):\n",
    "    '''Parse the training annotations from a CSV file.'''\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    f = pd.read_csv(csv_file, header=None, delim_whitespace=True, engine='python')\n",
    "    temp = []\n",
    "    for i, row in f.iterrows():\n",
    "        if len(temp) < 4:\n",
    "            # convert the cartesian pixel coordinates to polar coordinates\n",
    "            temp.append(raw_cartesian_to_polar_angles(row.to_list()))\n",
    "        else:\n",
    "            # the output frame\n",
    "            # convert the cartesian pixel coordinates to polar coordinates\n",
    "            next_frame = raw_cartesian_to_polar_angles(row.to_list())\n",
    "\n",
    "            # save\n",
    "            X_data.append(temp.copy())\n",
    "            y_data.append(next_frame.copy())\n",
    "\n",
    "            # add output frame to the inputs and remove the first\n",
    "            temp.pop(0)\n",
    "            temp.append(next_frame)\n",
    "    return X_data, y_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "BATCH_SIZE = 4000\n",
    "\n",
    "# load in all separate files\n",
    "X = []\n",
    "y = []\n",
    "for filename in tqdm([x for x in os.listdir(train_dir) if not x.startswith('.')]):\n",
    "    # load in a file\n",
    "    X_data, y_data = parse_training_annotations(os.path.join(train_dir, filename))\n",
    "    \n",
    "    # extract sequential batches and add them to the training data\n",
    "    for i in range(len(X_data) // BATCH_SIZE):\n",
    "        X_batch = X_data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "        y_batch = y_data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "        X.append(X_batch)\n",
    "        y.append(y_batch)\n",
    "\n",
    "num_batches = len(X)\n",
    "num_records = num_batches * BATCH_SIZE\n",
    "print(f'{num_records} training records spread over {num_batches} batches of size {BATCH_SIZE}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:35<00:00,  1.14it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "276000 training records spread over 69 batches of size 4000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# torch_X has n batches of size 4000, each sample is 4 frame, each frame is 4 value (sin,cos,sin,cos), e.g. torch.Size([69,4000,4,4])\n",
    "torch_X = torch.from_numpy(X)\n",
    "# torch_y has n batches of size 4000, each sample is a sequence of frames, unknown length, of 4 values, e.g. torch.Size([69,4000,4])\n",
    "torch_y = torch.from_numpy(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('cs152': conda)"
  },
  "interpreter": {
   "hash": "9950993fed0fd9aed4b27a856c953e397ab7787bcf7b4a95697366d9a811f382"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}